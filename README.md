# Hatespeech_BiLSTM

In this project we have taken wikipedia comments and try to detect the toxic comments. The comments on Wikipedia that have been flagged as toxic by human raters are included in the dataset. Here I have used Bidirectional LSTM to perform the detection. Bidirectional LSTM is a sequence model which contains two LSTM layers, one for processing input in the forward direction and the other for processing in the backward direction

Because Bidirectional Long Short-Term Memory (BiLSTM) networks can retain both past and future context in text, they are well-suited for detecting hate speech or poisonous remarks in datasets. Long-term dependencies in text can be handled by BiLSTMs, which is crucial for identifying intricate linguistic patterns in toxic comments that may contain several phrases or pages. 
